"""
Implementation of graph flow environment.

All environments are based on the same dynamics.

BanditEnv is a module that allows a learner to interact with environment in a
bandit setting.

MDPEnv is a module that allows the agent to interact with a discounted MDP
setting.

GraphMDP is a module that allows the agent to interact with the environment
taking into account the graphical structure of the problem.
"""
import networkx as nx
from networkx import traversal as T
import matplotlib.pyplot as plt
import numpy as np
from itertools import product

class GraphFlow:
    """
    The graph encoding the dynamics of the environments.
    """
    def __init__(self, name):
        self.G = self.generate_graph(name)
        self.name = name
        # keep the index of the sink
        self.sink = None
        for node in self.G.nodes:
            if self.G.nodes[node]['type'] == 'sink':
                self.sink = node
        self.depth = nx.dag_longest_path_length(self.G)
        self.layer_sizes = []
        for layer in T.bfs_layers(self.G, 1):
            self.layer_sizes.append(len(layer))


    def compute_flow(self):
        """
        Compute the flow generated by the given action profile.

        Input:
            - actions  : For each node the fraction of flow affected to each
                         node. actions is a dictionary with {edge: action}
        Output:
            - F : The total flow accross the network. If one or more edge are
                  above capacity the total flow is set to 0.
            - Invalid : A flag to highlight if the proposed flow is invalid
        """
        consistency = {node: 0 for node in self.G.nodes}

        for layer in T.bfs_layers(self.G, 1):
            for node in layer:
                for (_, nxt_nodes) in T.bfs_successors(self.G, node, depth_limit=1):
                    if len(nxt_nodes) > 0:
                        for nxt_node in nxt_nodes:
                            edge = self.G.edges[(node, nxt_node)]
                            flow = edge['flow']
                            if flow > edge['cap']: # overflow
                                return 0, True
                            consistency[node] -= flow
                            consistency[nxt_node] += flow

        # check the consistency of the solution
        for node, val in consistency.items():
            if self.G.nodes[node]['type'] == 'node' and val != 0:
                return 0, True # 0 flow the instruction are not valid
        return consistency[self.sink], False


    def set_context(self,edge_values, capacities):
        """
        Set the edges capacities.
        And the source node reserve.
        Input:
            - name  : The name of the graph
        """
        nx.set_edge_attributes(self.G, edge_values)
        nx.set_edge_attributes(self.G, capacities)

    def generate_graph(self, name):
        """
        Generate a graph layout:

        Input:
            - name : The name of the layout.
        Output:
            - G    : The graph
        """

        if name == 'path':
            G = nx.DiGraph()
            nodes = {1: (0, 0), 2: (1, 0), 3: (2, 0)}
            edges = [(1, 2), (2, 3)]

            for node, pos in nodes.items():
                G.add_node(node, pos=pos)

            for sender, receiver in edges:
                G.add_edge(sender, receiver)

            node_values = {1: {'type': 'source'},
                           2: {'type': 'node'},
                           3: {'type': 'sink'}}
            nx.set_node_attributes(G, node_values)

        else:
            print(f"Unknown graph of name: {name}")
        return G


class BanditEnv():

    def __init__(self):
        self.flowG = GraphFlow('path')
        self.name = 'path'
        self.atomic_actions = [0., 0.5, 1.0]
        self.N = len(self.flowG.G.nodes)
        self.E = len(self.flowG.G.edges)
        self.edges = self.flowG.G.edges
        self.action_space = None
        self.build_action_space()
        # we assume a unique context.
        self.context_space = [(1 for i in range(self.N))]
        self.possible_rewards = [0., 0.25, 0.5, 1.]

    def build_action_space(self):
        """
        The combinatorial action space consists of all the combination
        of atomic action, making sure that the total action from a node
        does not exceed 1.
        """
        action_space = list(product(self.atomic_actions, repeat=self.E))
        self.action_space = self.remove_illegal_actions(action_space)

    def remove_illegal_actions(self, action_space):
        """
        The action stipulate which fraction of the node current
        flow goes to each edges. Actions are considered illegal,
        if the sum of the fraction leaving a node exceeds 1.
        """
        # TODO: iterate through all nodes and make sure that all edges actions do not exceed 1.
        return action_space

    def act(self, k):
        """
        Play the specified actions in the environment
        Input:
            - k : Is the index of the selected action.

        Ouput:
            - reward : The reward obtained by the selected action profile.
        """
        action = self.action_space[k]
        action = {edge: {'flow': a} for edge, a in zip(self.edges, action)}
        nx.set_edge_attributes(self.flowG.G, action)
        reward, invalid = self.flowG.compute_flow()
        return reward, invalid

    def reset(self):
        if self.name == 'path':
            edge_values = {(1, 2): {'flow': 0.0},
                           (2, 3): {'flow': 0.0}}

            capacities = {(1, 2): {'cap': 1.0},
                          (2, 3): {'cap': 0.5}}

        else:
            exit()
        self.flowG.set_context(edge_values, capacities)
        return capacities


class PathMDP():
    def __init__(self):
        self.H = 2
        self.action_atomic = [0., 0.5, 1.0]
        self.state_atomic = [0., 0.25, 0.5, 1.0]
        self.reward_atomic = [0., 0.25, 0.5, 1.0]

    def reset(self):
        self.t = 0
        self.state = 1

    def act(self, a):
        nxt_state = a * self.state
        reward = nxt_state
        self.t += 1
        done = self.t > self.H
        self.state = nxt_state
        return nxt_state, reward, done


class MDPEnv():
    def __init__(self):
        """
        For the moment works only for a path style graph.

        The state space can ba factored into observation collected at each node of the correponding layer.
        The obsercation collected at a node consist of the current flow in the node as well as the capacity of each edge existing the node.

        Similarly the action at a given timestep can also be seen as the cartesian product of actions taken on each edge.

        This decomposition allows the factorisation of the transition function as well as the reward function.

        The atomic transition gives the probability of the next state.
        """
        # get the graph
        self.flowG = GraphFlow('path')

        # get H from the graph
        self.H = self.flowG.depth
        self.action_atomic = [0., 0.5, 1.0]
        self.state_atomic = [0., 0.25, 0.5, 1.0]
        self.nStates = self.flowG.layer_sizes
        self.reward_atomic = [0., 0.25, 0.5, 1.0]

        self.P = {}
        self.R = {}

        for s in self.state_atomic:
            for a in self.action_atomic:
                self.P[(s, a)] = np.zeros(len(self.state_atomic))
                for k, s_nxt in enumerate(self.state_atomic):
                    if s*a == s_nxt:
                        self.P[(s, a)][k] = 1

        # reward function??? 
        # is it
        print(self.P)

        # construct the action space
        # state index (t, x_1, ... x_k) -> idx
        layer_size = self.flowG.layer_sizes

        self.N = len(self.flowG.G.nodes)
        self.E = len(self.flowG.G.edges)
        self.edges = self.flowG.G.edges

    def act(self, k):
        """
        """
        done = False
        action = self.action_space[k]
        new_state = []
        for a, edge in zip(action, self.edges):
            curr = self.flowG.G.edges[edge]['flow']
            self.flowG.G.edges[edge]['flow'] = np.clip(curr + a, a_min=0.0, a_max=1.0)
            new_state.append(self.flowG.G.edges[edge]['flow'])
        reward, invalid = self.flowG.compute_flow()
        self.t += 1
        if self.t == 10:
            done = True
        return reward, new_state, invalid, done

    def reset(self):
        """
        """
        self.t = 0
        if self.name == 'path':
            edge_values = {(1, 2): {'flow': 0.0},
                           (2, 3): {'flow': 0.0}}

            capacities = {(1, 2): {'cap': 1.0},
                          (2, 3): {'cap': 0.5}}

        else:
            exit()
        self.flowG.set_context(edge_values, capacities)
        return capacities


def plot_graph_layout(G):
    fig, ax = plt.subplots(1, 1)
    pos = nx.get_node_attributes(G, 'pos')
    nx.draw(G, with_labels=True,
            pos=pos, ax=ax)
    plt.show()


def test_BanditEnv():
    env = BanditEnv()
    import matplotlib.pyplot as plt
    rs = []
    fig, ax = plt.subplots()
    xlabels = []
    values = []
    for k in np.arange(len(env.action_space)):
        env.reset()
        r, _ = env.act(k)
        ax.scatter(k, r, marker='x')
        xlabels.append(f"{env.action_space[k]}")
        values.append(k)
        ax.set_xticks(values, xlabels, rotation=45)
    plt.show()


def test_MDPEnv():
    env = MDPEnv()


def test_PathMDP():
    env = PathMDP()
    env.reset()
    for ep in range(10):
        done = False
        print(f"starting ep {ep}")
        while not done:
            a = np.random.choice(env.action_atomic)
            nxt_state, reward, done = env.act(a)

if __name__ == "__main__":
    #test_BanditEnv()
    #test_MDPEnv()
    test_PathMDP()
